{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "course": "Comp521F19",
    "problemset": 4,
    "section": "header"
   },
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h1>The University of North Carolina at Chapel Hill</h1>\n",
    "<h1>COMP 521 Files and Databases Fall 2020</h1>\n",
    "<h1 style=\"font-size: 200%;\">Problem Set 4</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "setup"
   },
   "source": [
    "---\n",
    "By default, SQlite only builds ISAM-tree index. In the following questions,\n",
    "you will need to write Python3 programs to simulate a hash index on a *(year, fips)* search key for the *Demographics*\n",
    "table in the <a href=\"http://csbio.unc.edu/mcmillan/Media/NCCOVID19.db\" download>NCCOVID19.db</a> database. \n",
    "A function to get the hash-bucket pageid for records in *Demographics*\n",
    "table is provided below:\n",
    "\n",
    "<pre>\n",
    "    def getPageId(year, fips):\n",
    "        return int((fips + 7*year) % 512)\n",
    "</pre>\n",
    "\n",
    "Suppose each *(year, fips, pageId)* tuple in the hash index uses 10 bytes and a single page stores at most 400\n",
    "*(year, fips, pageId)* pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iSQL\n",
    "query = iSQL.parser(\"NCCOVID19.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 1,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 1:** How many buckets will overflow? What is the average number of *(year, fips, pageID)* tuples in a bucket? Suppose a page can hold at most 128 *Demographics* records, on average how many pages you need to fetch to select all *Demographics* of a given county in a given year (you should assume that the county and year are valid entries for the given database)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 1,
    "section": "answer"
   },
   "source": [
    "Overflow Buckets: 252\n",
    "Average number of search-key-page-id records per bucket: 553.00390625\n",
    "Average number of Demographics page accesses per year-fips query: 2.5885885885885886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1406, 1140, 1596, 1501, 1501, 1349, 1178, 1425, 988, 1653, 1311, 1539, 1197, 1178, 1254, 988, 1463, 1311, 1387, 1235, 1083, 1254, 912, 1482, 1216, 1387, 1140, 1121, 1064, 912, 1330, 1216, 1216, 1140, 988, 1064, 722, 1330, 1140, 1235, 950, 1007, 1064, 722, 1140, 1159, 1064, 950, 836, 1045, 646, 1140, 969, 1064, 760, 855, 874, 646, 950, 969, 931, 760, 779, 874, 570, 969, 779, 931, 722, 779, 741, 570, 779, 779, 741, 741, 589, 741, 494, 798, 589, 760, 551, 589, 665, 494, 665, 589, 608, 551, 532, 665, 380, 684, 399, 608, 456, 532, 475, 380, 494, 399, 418, 456, 342, 475, 190, 494, 266, 418, 266, 361, 323, 190, 342, 266, 304, 266, 190, 323, 76, 342, 152, 304, 190, 190, 133, 76, 190, 152, 114, 190, 38, 133, 0, 190, 0, 114, 0, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 190, 0, 76, 0, 38, 0, 76, 190, 38, 76, 57, 38, 76, 76, 266, 38, 190, 57, 190, 76, 266, 266, 190, 190, 247, 190, 171, 266, 342, 209, 323, 247, 266, 190, 437, 342, 285, 323, 323, 266, 304, 456, 380, 342, 475, 323, 380, 304, 627, 380, 532, 475, 399, 399, 399, 646, 570, 608, 589, 361, 513, 418, 836, 570, 684, 627, 589, 532, 494, 836, 760, 684, 703, 589, 608, 513, 931, 760, 760, 703, 798, 608, 684, 931, 950, 760, 798, 798, 798, 741, 1026, 950, 931, 798, 874, 836, 912, 1026, 1083, 931, 1026, 855, 912, 969, 1159, 1102, 1026, 1045, 931, 912, 1121, 1178, 1159, 1045, 1083, 969, 1045, 1140, 1368, 1159, 1083, 1102, 1102, 1064, 1311, 1425, 1349, 1121, 1292, 1102, 1178, 1349, 1634, 1349, 1311, 1311, 1197, 1178, 1425, 1672, 1425, 1368, 1387, 1197, 1254, 1501, 1881, 1235, 1463, 1273, 1387, 1216, 1672, 1748, 1425, 1406, 1425, 1387, 1406, 1558, 1862, 1368, 1520, 1292, 1520, 1216, 1691, 1710, 1482, 1406, 1425, 1368, 1292, 1539, 1786, 1406, 1482, 1254, 1577, 1178, 1653, 1596, 1596, 1292, 1387, 1463, 1254, 1596, 1672, 1596, 1482, 1235, 1539, 1140, 1729, 1482, 1691, 1311, 1292]\n",
      "\n",
      "Overflow Buckets: 252\n",
      "Average number of search-key-page-id records per bucket: 553.00390625\n",
      "Average number of Demographics page accesses per year-fips query: 2.5885885885885886\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def getPageId(year, fips):\n",
    "    return int((fips + 7*year) % 512)\n",
    "\n",
    "db = sqlite3.connect(\"NCCOVID19.db\")\n",
    "db.row_factory = sqlite3.Row\n",
    "db.text_factory = str\n",
    "cursor = db.cursor()\n",
    "bucket = [0 for i in range(512)]\n",
    "\n",
    "for row in cursor.execute(\"SELECT * FROM Demographics\"):\n",
    "    pageId = getPageId(row['year'], row['fips'])\n",
    "    bucket[pageId] += 1\n",
    "print(bucket)\n",
    "print()\n",
    "\n",
    "overflow = sum([count > 400 for count in bucket])\n",
    "print('Overflow Buckets:', overflow)\n",
    "\n",
    "average = sum(bucket)/len(bucket)\n",
    "print('Average number of search-key-page-id records per bucket:', average)\n",
    "\n",
    "pageAccess = sum([(count+399)//400 for count in bucket if count > 0])/sum([count > 0 for count in bucket])\n",
    "print('Average number of Demographics page accesses per year-fips query:', pageAccess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 2,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 2:** Assuming that the *Demographics* table occupies 2240 pages. How many passes are required to sort the table by (*year*, *fips*) if 20 buffer-pages are allocated for the sort? What would be the minimum number of buffer pages required to perform the same sort in 2-passes?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 2,
    "section": "answer"
   },
   "source": [
    "Number of passes using 20 buffer-pages: 3\n",
    "Number of buffer-pages required to sort in 2 passes: 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passes using 20 buffer-pages: 3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print('Number of passes using 20 buffer-pages:', 1 + (math.ceil(math.log(math.ceil(2240 / 20), 20 - 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "setup"
   },
   "source": [
    "---\n",
    "In the following problems consider evaluation of the following query:\n",
    "\n",
    "<code>\n",
    "    SELECT D.year, C.name, SUM(count) as population\n",
    "    FROM County C, Demographics D\n",
    "    WHERE C.fips=D.fips\n",
    "    GROUP BY D.year, D.fips\n",
    "</code>\n",
    "\n",
    "Assume the *County* table occupies 3 pages and has 100 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 3,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 3:** Assume that an index-nested loop is used to evaluate the query as described in the following pseudo code:\n",
    "\n",
    "<code>\n",
    "1)    for each page of County:\n",
    "2)        for each county record in page:\n",
    "3)            for each year in demographics records:\n",
    "4)                population = 0\n",
    "4)                Use year-fips hash index from Problem 1 to find the hash-bucket with relevant Demographics records\n",
    "5)                Load pages in hash-bucket chain in buffer pages\n",
    "6)                Sort relevant (year,fips,pageID) tuples by pageID\n",
    "7)                Read each page with distinct pageID\n",
    "8)                Scan page for matching year and fips values and add count to population\n",
    "9)                Output (Demographics.year, County.name, population)\n",
    "</code>\n",
    "\n",
    "Which numbered lines from the given pseudo code require loading pages from disk? You can assume that demographic records are approximately clustered by year and fips, and that the pageIDs for *a group of year-fips records will span 6 pages* on average. Estimate the number pages read to perform this query. Note this question is only asking for the number of pages *read*, the number of pages *written* is data dependent."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 3,
    "section": "answer"
   },
   "source": [
    "A list of line numbers that load pages: 1, 5, 7\n",
    "How many page reads: 3 + (100 * 21 * (2.5886 + 6)) = 18039.06"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notes\n",
    "-------------------------\n",
    "100 -> number of counties\n",
    " 21 -> number of years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 4,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 4:** Assume that the Sort-Merge loop decribed in **Problem 2** using 20 buffer pages is used to evaluate the query as described in the following pseudo code:\n",
    "\n",
    "<code>\n",
    "1)    External Sort Demographics Table by (year, fips)\n",
    "2)    Read County Table as C and sort in memory by fips\n",
    "3)    previousYear = 0\n",
    "4)    for D in sorted demographics records:\n",
    "5)        if (D.year > previousYear):\n",
    "6)            previousYear = D.year\n",
    "7)            fips = C.fips\n",
    "8)            population = 0\n",
    "10)       while (D.fips > fips):\n",
    "11)           Output (D.year, C.name, population)\n",
    "12)           C.next()\n",
    "12)           fips = C.fips\n",
    "13)           population = 0\n",
    "14)       population += D.count\n",
    "15)   Output (D.year, C.name, population)\n",
    "</code>\n",
    "\n",
    "Which numbered lines from the given pseudo code require loading pages from disk? Estimate the number pages read to perform this query. Note this question is only asking for the number of pages *read*, the number of pages *written* is data dependent."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 4,
    "section": "answer"
   },
   "source": [
    "A list of line numbers that load pages: 1, 2, 4\n",
    "How many page reads: 3*2240 + 2240 + 3 = 8963"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 5,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 5:** Consider the following Functional Dependencies (FDs) that govern the Demographics table whose attributes *(fips, year, race, sex, agelo, agehi, count)* map to the following variable names FYRSLHC: \n",
    "\n",
    "\n",
    "<div style=\"margin:20px 250px\">\n",
    "FYRSL &rarr; FYRSLHC<br>H &rarr; L\n",
    "</div>\n",
    "\n",
    "Based on the given FDs, is this table in 3NF? Explain why or why not."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 5,
    "section": "answer"
   },
   "source": [
    "The table is not in 3NF because it includes the following transitive dependency:\n",
    "\n",
    "FYRSL -> H -> L (which is in a key)\n",
    "\n",
    "and FDs of the form X -> A are in 3NF if:\n",
    "\n",
    "1) A is part of some key, and\n",
    "2) X is not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 6,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 6:** Next, based on the FDs in **Problem 5**, propose a decomposition of Demographics that achieves BCNF. Express this decompostion as two CREATE TABLE commands with primary key declarations."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 6,
    "section": "answer"
   },
   "source": [
    "CREATE TABLE IF NOT EXISTS DemographicsBCNF (\n",
    "    fips    INTEGER,\n",
    "    year    INTEGER,\n",
    "    race    TEXT,\n",
    "    sex     TEXT,\n",
    "    agehi   INTEGER,\n",
    "    count   INTEGER,\n",
    "    PRIMARY KEY(fips, year, race, sex, agehi),\n",
    "    FOREIGN KEY(fips)  REFERENCES County(fips),\n",
    "    FOREIGN KEY(agehi) REFERENCES Ages(agehi)\n",
    ")\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS Ages (\n",
    "    agelo   INTEGER,\n",
    "    agehi   INTEGER,\n",
    "    PRIMARY KEY(agehi)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "number": 7,
    "section": "problem"
   },
   "source": [
    "---\n",
    "**Problem 7:** Given your decomposition of Demographics from **Problem 6**, how many rows will be in each resulting table, and is a natural join of these two tables lossless?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "number": 7,
    "section": "answer"
   },
   "source": [
    "Rows in two tables: 283138 rows in the DemographicsBCNF table and 19 rows in the Ages table.\n",
    "\n",
    "Is a natural join of these tables lossless: Yes, because for every entry of high, there is only one entry of low. Therefore, we cannot increase nor decrease the number of rows in the first table. Thus, when performing the join, we would still have the same number of rows; and since the number of rows in the original table is equal to the number of rows in the new table, this is a lossless join."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: BCNF guarantees the natural join of the two table to be lossless because everything is a primary key on the left-hand-side of the functional dependency."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
